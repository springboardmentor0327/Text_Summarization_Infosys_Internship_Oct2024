{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Libraries**"
      ],
      "metadata": {
        "id": "PMQchBTI69-x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvFdeWk5BC02",
        "outputId": "70eaf7ac-7ace-4df2-cf8c-7866f6967feb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import string\n",
        "from string import punctuation\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize, punkt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Threshold-Based Extractive Summarization Technique**\n",
        "\n",
        "\n",
        "This function generates an extractive summary by selecting sentences with scores above a specified threshold. It evaluates each sentence's relevance using pre-calculated scores and compiles the most important sentences into a concise summary."
      ],
      "metadata": {
        "id": "Nv-6BKSOZgDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = ''' Those Who Are Resilient Stay In The Game Longer\n",
        "“On the mountains of truth you can never climb in vain: either you will reach a point higher up today, or you will be training your powers so that you will be able to climb higher tomorrow.” — Friedrich Nietzsche\n",
        "Challenges and setbacks are not meant to defeat you, but promote you. However, I realise after many years of defeats, it can crush your spirit and it is easier to give up than risk further setbacks and disappointments. Have you experienced this before? To be honest, I don’t have the answers. I can’t tell you what the right course of action is; only you will know. However, it’s important not to be discouraged by failure when pursuing a goal or a dream, since failure itself means different things to different people. To a person with a Fixed Mindset failure is a blow to their self-esteem, yet to a person with a Growth Mindset, it’s an opportunity to improve and find new ways to overcome their obstacles. Same failure, yet different responses. Who is right and who is wrong? Neither. Each person has a different mindset that decides their outcome. Those who are resilient stay in the game longer and draw on their inner means to succeed.\n",
        "I’ve coached many clients who gave up after many years toiling away at their respective goal or dream. It was at that point their biggest breakthrough came. Perhaps all those years of perseverance finally paid off. It was the 19th Century’s minister Henry Ward Beecher who once said: “One’s best success comes after their greatest disappointments.” No one knows what the future holds, so your only guide is whether you can endure repeated defeats and disappointments and still pursue your dream. Consider the advice from the American academic and psychologist Angela Duckworth who writes in Grit: The Power of Passion and Perseverance: “Many of us, it seems, quit what we start far too early and far too often. Even more than the effort a gritty person puts in on a single day, what matters is that they wake up the next day, and the next, ready to get on that treadmill and keep going.”\n",
        "I know one thing for certain: don’t settle for less than what you’re capable of, but strive for something bigger. Some of you reading this might identify with this message because it resonates with you on a deeper level. For others, at the end of their tether the message might be nothing more than a trivial pep talk. What I wish to convey irrespective of where you are in your journey is: NEVER settle for less. If you settle for less, you will receive less than you deserve and convince yourself you are justified to receive it.\n",
        "“Two people on a precipice over Yosemite Valley” by Nathan Shipps on Unsplash\n",
        "Develop A Powerful Vision Of What You Want\n",
        "“Your problem is to bridge the gap which exists between where you are now and the goal you intend to reach.” — Earl Nightingale\n",
        "I recall a passage my father often used growing up in 1990s: “Don’t tell me your problems unless you’ve spent weeks trying to solve them yourself.” That advice has echoed in my mind for decades and became my motivator. Don’t leave it to other people or outside circumstances to motivate you because you will be let down every time. It must come from within you. Gnaw away at your problems until you solve them or find a solution. Problems are not stop signs, they are advising you that more work is required to overcome them. Most times, problems help you gain a skill or develop the resources to succeed later. So embrace your challenges and develop the grit to push past them instead of retreat in resignation. Where are you settling in your life right now? Could you be you playing for bigger stakes than you are? Are you willing to play bigger even if it means repeated failures and setbacks? You should ask yourself these questions to decide whether you’re willing to put yourself on the line or settle for less. And that’s fine if you’re content to receive less, as long as you’re not regretful later.\n",
        "If you have not achieved the success you deserve and are considering giving up, will you regret it in a few years or decades from now? Only you can answer that, but you should carve out time to discover your motivation for pursuing your goals. It’s a fact, if you don’t know what you want you’ll get what life hands you and it may not be in your best interest, affirms author Larry Weidel: “Winners know that if you don’t figure out what you want, you’ll get whatever life hands you.” The key is to develop a powerful vision of what you want and hold that image in your mind. Nurture it daily and give it life by taking purposeful action towards it.\n",
        "Vision + desire + dedication + patience + daily action leads to astonishing success. Are you willing to commit to this way of life or jump ship at the first sign of failure? I’m amused when I read questions written by millennials on Quora who ask how they can become rich and famous or the next Elon Musk. Success is a fickle and long game with highs and lows. Similarly, there are no assurances even if you’re an overnight sensation, to sustain it for long, particularly if you don’t have the mental and emotional means to endure it. This means you must rely on the one true constant in your favour: your personal development. The more you grow, the more you gain in terms of financial resources, status, success — simple. If you leave it to outside conditions to dictate your circumstances, you are rolling the dice on your future.\n",
        "So become intentional on what you want out of life. Commit to it. Nurture your dreams. Focus on your development and if you want to give up, know what’s involved before you take the plunge. Because I assure you, someone out there right now is working harder than you, reading more books, sleeping less and sacrificing all they have to realise their dreams and it may contest with yours. Don’t leave your dreams to chance. '''"
      ],
      "metadata": {
        "id": "ScfRALlb64Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords=list(STOP_WORDS)\n",
        "stopwords[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8NPTuMA-DrL",
        "outputId": "74aeb145-fb0a-4787-c9c2-1610613e9d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['under',\n",
              " 'around',\n",
              " 'my',\n",
              " 'is',\n",
              " '’d',\n",
              " '’ll',\n",
              " 'made',\n",
              " 'same',\n",
              " 'whoever',\n",
              " 'therefore',\n",
              " 'seems',\n",
              " 'put',\n",
              " 'used',\n",
              " 'i',\n",
              " 'another',\n",
              " 'however',\n",
              " 'towards',\n",
              " 'about',\n",
              " 'something',\n",
              " 'nor',\n",
              " \"'re\",\n",
              " 'get',\n",
              " 'hers',\n",
              " 'throughout',\n",
              " \"'d\",\n",
              " 'elsewhere',\n",
              " 'six',\n",
              " 'who',\n",
              " 'rather',\n",
              " 'while',\n",
              " 'latterly',\n",
              " 'mine',\n",
              " 'she',\n",
              " 'thereupon',\n",
              " 'may',\n",
              " 'full',\n",
              " 'hereby',\n",
              " '‘d',\n",
              " 'fifty',\n",
              " 'though',\n",
              " 'your',\n",
              " 'alone',\n",
              " 'using',\n",
              " 'being',\n",
              " 'herself',\n",
              " 'whom',\n",
              " 'during',\n",
              " 'so',\n",
              " 'fifteen',\n",
              " '‘re',\n",
              " 'please',\n",
              " 'latter',\n",
              " 'nobody',\n",
              " 'sixty',\n",
              " 'from',\n",
              " 'without',\n",
              " 'really',\n",
              " 'seemed',\n",
              " 'yourself',\n",
              " 'nevertheless',\n",
              " 'just',\n",
              " 'seeming',\n",
              " 'unless',\n",
              " 'ever',\n",
              " 'do',\n",
              " 'three',\n",
              " 'whither',\n",
              " 'behind',\n",
              " 'call',\n",
              " 'anyway',\n",
              " 'did',\n",
              " 'this',\n",
              " 'per',\n",
              " 'thereby',\n",
              " 'hundred',\n",
              " '’re',\n",
              " 'how',\n",
              " 'against',\n",
              " 'us',\n",
              " 'along',\n",
              " 'on',\n",
              " 'had',\n",
              " 'beyond',\n",
              " 'becoming',\n",
              " 'less',\n",
              " 'yet',\n",
              " 'move',\n",
              " 'front',\n",
              " 'anywhere',\n",
              " 'across',\n",
              " 'upon',\n",
              " 'someone',\n",
              " 'take',\n",
              " 'be',\n",
              " 'down',\n",
              " 'thence',\n",
              " 'every',\n",
              " 'last',\n",
              " 'hence',\n",
              " 're']"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.load('en_core_web_sm')\n",
        "doc=nlp(text)\n",
        "tokens=[token.text for token in doc]\n",
        "tokens[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPrQDLv1-azI",
        "outputId": "f4572069-3109-421d-c6f0-429d99fa26b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ',\n",
              " 'Those',\n",
              " 'Who',\n",
              " 'Are',\n",
              " 'Resilient',\n",
              " 'Stay',\n",
              " 'In',\n",
              " 'The',\n",
              " 'Game',\n",
              " 'Longer',\n",
              " '\\n',\n",
              " '“',\n",
              " 'On',\n",
              " 'the',\n",
              " 'mountains',\n",
              " 'of',\n",
              " 'truth',\n",
              " 'you',\n",
              " 'can',\n",
              " 'never',\n",
              " 'climb',\n",
              " 'in',\n",
              " 'vain',\n",
              " ':',\n",
              " 'either',\n",
              " 'you',\n",
              " 'will',\n",
              " 'reach',\n",
              " 'a',\n",
              " 'point',\n",
              " 'higher',\n",
              " 'up',\n",
              " 'today',\n",
              " ',',\n",
              " 'or',\n",
              " 'you',\n",
              " 'will',\n",
              " 'be',\n",
              " 'training',\n",
              " 'your',\n",
              " 'powers',\n",
              " 'so',\n",
              " 'that',\n",
              " 'you',\n",
              " 'will',\n",
              " 'be',\n",
              " 'able',\n",
              " 'to',\n",
              " 'climb',\n",
              " 'higher',\n",
              " 'tomorrow',\n",
              " '.',\n",
              " '”',\n",
              " '\\u200a',\n",
              " '—',\n",
              " '\\u200a',\n",
              " 'Friedrich',\n",
              " 'Nietzsche',\n",
              " '\\n',\n",
              " 'Challenges',\n",
              " 'and',\n",
              " 'setbacks',\n",
              " 'are',\n",
              " 'not',\n",
              " 'meant',\n",
              " 'to',\n",
              " 'defeat',\n",
              " 'you',\n",
              " ',',\n",
              " 'but',\n",
              " 'promote',\n",
              " 'you',\n",
              " '.',\n",
              " 'However',\n",
              " ',',\n",
              " 'I',\n",
              " 'realise',\n",
              " 'after',\n",
              " 'many',\n",
              " 'years',\n",
              " 'of',\n",
              " 'defeats',\n",
              " ',',\n",
              " 'it',\n",
              " 'can',\n",
              " 'crush',\n",
              " 'your',\n",
              " 'spirit',\n",
              " 'and',\n",
              " 'it',\n",
              " 'is',\n",
              " 'easier',\n",
              " 'to',\n",
              " 'give',\n",
              " 'up',\n",
              " 'than',\n",
              " 'risk',\n",
              " 'further',\n",
              " 'setbacks',\n",
              " 'and']"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_frequency_table(text) -> dict:\n",
        "    stopWords = set(stopwords.words(\"english\"))\n",
        "    words = word_tokenize(text)\n",
        "    ps = PorterStemmer()\n",
        "\n",
        "    freqTable = dict()\n",
        "    for word in words:\n",
        "        word = ps.stem(word)\n",
        "        if word in stopWords:\n",
        "            continue\n",
        "        if word in freqTable:\n",
        "            freqTable[word] += 1\n",
        "        else:\n",
        "            freqTable[word] = 1\n",
        "    return freqTable\n",
        "\n",
        "freq_table = create_frequency_table(text)\n",
        "print(freq_table)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_FIsjEPGi8P",
        "outputId": "2c9b20d5-c893-41f0-fa91-588bd465312f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'resili': 2, 'stay': 2, 'game': 3, 'longer': 2, '“': 7, 'mountain': 1, 'truth': 1, 'never': 2, 'climb': 2, 'vain': 1, ':': 9, 'either': 1, 'reach': 1, 'point': 2, 'higher': 2, 'today': 1, ',': 38, 'train': 1, 'power': 4, 'abl': 1, 'tomorrow.': 1, '”': 7, '—': 3, 'friedrich': 1, 'nietzsch': 1, 'challeng': 2, 'setback': 3, 'meant': 1, 'defeat': 3, 'promot': 1, '.': 45, 'howev': 2, 'realis': 2, 'mani': 4, 'year': 4, 'crush': 1, 'spirit': 1, 'easier': 1, 'give': 4, 'risk': 1, 'disappoint': 2, 'experienc': 1, 'thi': 5, 'befor': 2, '?': 7, 'honest': 1, '’': 26, 'answer': 2, 'tell': 2, 'right': 4, 'cours': 1, 'action': 3, ';': 1, 'onli': 3, 'know': 6, 'import': 1, 'discourag': 1, 'failur': 6, 'pursu': 3, 'goal': 4, 'dream': 6, 'sinc': 1, 'mean': 5, 'differ': 4, 'thing': 2, 'peopl': 3, 'person': 5, 'fix': 1, 'mindset': 3, 'blow': 1, 'self-esteem': 1, 'yet': 2, 'growth': 1, 'opportun': 1, 'improv': 1, 'find': 2, 'new': 1, 'way': 2, 'overcom': 2, 'obstacl': 1, 'respons': 1, 'wrong': 1, 'neither': 1, 'ha': 2, 'decid': 2, 'outcom': 1, 'draw': 1, 'inner': 1, 'succeed': 2, 'coach': 1, 'client': 1, 'gave': 1, 'toil': 1, 'away': 2, 'respect': 1, 'wa': 2, 'biggest': 1, 'breakthrough': 1, 'came': 1, 'perhap': 1, 'persever': 2, 'final': 1, 'paid': 1, '19th': 1, 'centuri': 1, 'minist': 1, 'henri': 1, 'ward': 1, 'beecher': 1, 'onc': 1, 'said': 1, 'one': 4, 'best': 2, 'success': 5, 'come': 2, 'greatest': 1, 'disappointments.': 1, 'futur': 2, 'hold': 2, 'guid': 1, 'whether': 2, 'endur': 2, 'repeat': 2, 'still': 1, 'consid': 2, 'advic': 2, 'american': 1, 'academ': 1, 'psychologist': 1, 'angela': 1, 'duckworth': 1, 'write': 1, 'grit': 2, 'passion': 1, 'us': 1, 'seem': 1, 'quit': 1, 'start': 1, 'far': 2, 'earli': 1, 'often': 2, 'even': 3, 'effort': 1, 'gritti': 1, 'put': 2, 'singl': 1, 'day': 2, 'matter': 1, 'wake': 1, 'next': 3, 'readi': 1, 'get': 3, 'treadmil': 1, 'keep': 1, 'going.': 1, 'certain': 1, 'settl': 5, 'less': 7, 'capabl': 1, 'strive': 1, 'someth': 1, 'bigger': 3, 'read': 3, 'might': 2, 'identifi': 1, 'messag': 2, 'becaus': 3, 'reson': 1, 'deeper': 1, 'level': 1, 'end': 1, 'tether': 1, 'noth': 1, 'trivial': 1, 'pep': 1, 'talk': 1, 'wish': 1, 'convey': 1, 'irrespect': 1, 'journey': 1, 'receiv': 3, 'deserv': 2, 'convinc': 1, 'justifi': 1, 'two': 1, 'precipic': 1, 'yosemit': 1, 'valley': 1, 'nathan': 1, 'shipp': 1, 'unsplash': 1, 'develop': 6, 'vision': 3, 'want': 6, 'problem': 5, 'bridg': 1, 'gap': 1, 'exist': 1, 'intend': 1, 'reach.': 1, 'earl': 1, 'nightingal': 1, 'recal': 1, 'passag': 1, 'father': 1, 'use': 1, 'grow': 2, '1990': 1, 'unless': 1, 'spent': 1, 'week': 1, 'tri': 1, 'solv': 2, 'yourself.': 1, 'echo': 1, 'mind': 2, 'decad': 2, 'becam': 1, 'motiv': 3, 'leav': 3, 'outsid': 2, 'circumst': 2, 'let': 1, 'everi': 1, 'time': 3, 'must': 2, 'within': 1, 'gnaw': 1, 'solut': 1, 'stop': 1, 'sign': 2, 'advis': 1, 'work': 2, 'requir': 1, 'help': 1, 'gain': 2, 'skill': 1, 'resourc': 2, 'later': 2, 'embrac': 1, 'push': 1, 'past': 1, 'instead': 1, 'retreat': 1, 'resign': 1, 'life': 6, 'could': 1, 'play': 2, 'stake': 1, 'ask': 2, 'question': 2, 'line': 1, 'fine': 1, 'content': 1, 'long': 3, 'regret': 2, 'achiev': 1, 'carv': 1, 'discov': 1, 'fact': 1, 'hand': 2, 'may': 2, 'interest': 1, 'affirm': 1, 'author': 1, 'larri': 1, 'weidel': 1, 'winner': 1, 'figur': 1, 'whatev': 1, 'you.': 1, 'key': 1, 'imag': 1, 'nurtur': 2, 'daili': 2, 'take': 2, 'purpos': 1, 'toward': 1, '+': 4, 'desir': 1, 'dedic': 1, 'patienc': 1, 'lead': 1, 'astonish': 1, 'commit': 2, 'jump': 1, 'ship': 1, 'first': 1, 'amus': 1, 'written': 1, 'millenni': 1, 'quora': 1, 'becom': 2, 'rich': 1, 'famou': 1, 'elon': 1, 'musk': 1, 'fickl': 1, 'high': 1, 'low': 1, 'similarli': 1, 'assur': 2, 'overnight': 1, 'sensat': 1, 'sustain': 1, 'particularli': 1, 'mental': 1, 'emot': 1, 'reli': 1, 'true': 1, 'constant': 1, 'favour': 1, 'term': 1, 'financi': 1, 'statu': 1, 'simpl': 1, 'condit': 1, 'dictat': 1, 'roll': 1, 'dice': 1, 'intent': 1, 'focu': 1, 'involv': 1, 'plung': 1, 'someon': 1, 'harder': 1, 'book': 1, 'sleep': 1, 'sacrif': 1, 'contest': 1, 'chanc': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlKJOyBsGpaV",
        "outputId": "9a04b592-c241-45be-f884-727e37a1c4b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Those Who Are Resilient Stay In The Game Longer\\n“On the mountains of truth you can never climb in vain: either you will reach a point higher up today, or you will be training your powers so that you will be able to climb higher tomorrow.”\\u200a—\\u200aFriedrich Nietzsche\\nChallenges and setbacks are not meant to defeat you, but promote you.',\n",
              " 'However, I realise after many years of defeats, it can crush your spirit and it is easier to give up than risk further setbacks and disappointments.',\n",
              " 'Have you experienced this before?',\n",
              " 'To be honest, I don’t have the answers.',\n",
              " 'I can’t tell you what the right course of action is; only you will know.',\n",
              " 'However, it’s important not to be discouraged by failure when pursuing a goal or a dream, since failure itself means different things to different people.',\n",
              " 'To a person with a Fixed Mindset failure is a blow to their self-esteem, yet to a person with a Growth Mindset, it’s an opportunity to improve and find new ways to overcome their obstacles.',\n",
              " 'Same failure, yet different responses.',\n",
              " 'Who is right and who is wrong?',\n",
              " 'Neither.',\n",
              " 'Each person has a different mindset that decides their outcome.',\n",
              " 'Those who are resilient stay in the game longer and draw on their inner means to succeed.',\n",
              " 'I’ve coached many clients who gave up after many years toiling away at their respective goal or dream.',\n",
              " 'It was at that point their biggest breakthrough came.',\n",
              " 'Perhaps all those years of perseverance finally paid off.',\n",
              " 'It was the 19th Century’s minister Henry Ward Beecher who once said: “One’s best success comes after their greatest disappointments.” No one knows what the future holds, so your only guide is whether you can endure repeated defeats and disappointments and still pursue your dream.',\n",
              " 'Consider the advice from the American academic and psychologist Angela Duckworth who writes in Grit: The Power of Passion and Perseverance: “Many of us, it seems, quit what we start far too early and far too often.',\n",
              " 'Even more than the effort a gritty person puts in on a single day, what matters is that they wake up the next day, and the next, ready to get on that treadmill and keep going.”\\nI know one thing for certain: don’t settle for less than what you’re capable of, but strive for something bigger.',\n",
              " 'Some of you reading this might identify with this message because it resonates with you on a deeper level.',\n",
              " 'For others, at the end of their tether the message might be nothing more than a trivial pep talk.',\n",
              " 'What I wish to convey irrespective of where you are in your journey is: NEVER settle for less.',\n",
              " 'If you settle for less, you will receive less than you deserve and convince yourself you are justified to receive it.',\n",
              " '“Two people on a precipice over Yosemite Valley” by Nathan Shipps on Unsplash\\nDevelop A Powerful Vision Of What You Want\\n“Your problem is to bridge the gap which exists between where you are now and the goal you intend to reach.”\\u200a—\\u200aEarl Nightingale\\nI recall a passage my father often used growing up in 1990s: “Don’t tell me your problems unless you’ve spent weeks trying to solve them yourself.” That advice has echoed in my mind for decades and became my motivator.',\n",
              " 'Don’t leave it to other people or outside circumstances to motivate you because you will be let down every time.',\n",
              " 'It must come from within you.',\n",
              " 'Gnaw away at your problems until you solve them or find a solution.',\n",
              " 'Problems are not stop signs, they are advising you that more work is required to overcome them.',\n",
              " 'Most times, problems help you gain a skill or develop the resources to succeed later.',\n",
              " 'So embrace your challenges and develop the grit to push past them instead of retreat in resignation.',\n",
              " 'Where are you settling in your life right now?',\n",
              " 'Could you be you playing for bigger stakes than you are?',\n",
              " 'Are you willing to play bigger even if it means repeated failures and setbacks?',\n",
              " 'You should ask yourself these questions to decide whether you’re willing to put yourself on the line or settle for less.',\n",
              " 'And that’s fine if you’re content to receive less, as long as you’re not regretful later.',\n",
              " 'If you have not achieved the success you deserve and are considering giving up, will you regret it in a few years or decades from now?',\n",
              " 'Only you can answer that, but you should carve out time to discover your motivation for pursuing your goals.',\n",
              " 'It’s a fact, if you don’t know what you want you’ll get what life hands you and it may not be in your best interest, affirms author Larry Weidel: “Winners know that if you don’t figure out what you want, you’ll get whatever life hands you.” The key is to develop a powerful vision of what you want and hold that image in your mind.',\n",
              " 'Nurture it daily and give it life by taking purposeful action towards it.',\n",
              " 'Vision + desire + dedication + patience + daily action leads to astonishing success.',\n",
              " 'Are you willing to commit to this way of life or jump ship at the first sign of failure?',\n",
              " 'I’m amused when I read questions written by millennials on Quora who ask how they can become rich and famous or the next Elon Musk.',\n",
              " 'Success is a fickle and long game with highs and lows.',\n",
              " 'Similarly, there are no assurances even if you’re an overnight sensation, to sustain it for long, particularly if you don’t have the mental and emotional means to endure it.',\n",
              " 'This means you must rely on the one true constant in your favour: your personal development.',\n",
              " 'The more you grow, the more you gain in terms of financial resources, status, success\\u200a—\\u200asimple.',\n",
              " 'If you leave it to outside conditions to dictate your circumstances, you are rolling the dice on your future.',\n",
              " 'So become intentional on what you want out of life.',\n",
              " 'Commit to it.',\n",
              " 'Nurture your dreams.',\n",
              " 'Focus on your development and if you want to give up, know what’s involved before you take the plunge.',\n",
              " 'Because I assure you, someone out there right now is working harder than you, reading more books, sleeping less and sacrificing all they have to realise their dreams and it may contest with yours.',\n",
              " 'Don’t leave your dreams to chance.']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score_sentences(sentences, freqTable) -> dict:\n",
        "    sentenceValue = dict()\n",
        "\n",
        "    for sentence in sentences:\n",
        "        word_count_in_sentence = (len(word_tokenize(sentence)))\n",
        "        for wordValue in freqTable:\n",
        "            if wordValue in sentence.lower():\n",
        "                if sentence[:10] in sentenceValue:\n",
        "                    sentenceValue[sentence[:10]] += freqTable[wordValue]\n",
        "                else:\n",
        "                    sentenceValue[sentence[:10]] = freqTable[wordValue]\n",
        "\n",
        "        sentenceValue[sentence[:10]] = sentenceValue[sentence[:10]] // word_count_in_sentence\n",
        "\n",
        "    return sentenceValue\n",
        "\n",
        "sentences = sent_tokenize(text)\n",
        "sentence_scores = score_sentences(sentences, freq_table)\n",
        "print(sentence_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxI56lwTR5DD",
        "outputId": "fc4c1a57-0029-4e3f-dce8-dc4661629974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' Those Who': 2, 'However, I': 3, 'Have you e': 2, 'To be hone': 9, 'I can’t te': 4, 'However, i': 5, 'To a perso': 3, 'Same failu': 13, 'Who is rig': 1, 'Neither.': 23, 'Each perso': 6, 'Those who ': 3, 'I’ve coach': 4, 'It was at ': 5, 'Perhaps al': 5, 'It was the': 3, 'Consider t': 3, 'Even more ': 2, 'Some of yo': 3, 'For others': 4, 'What I wis': 3, 'If you set': 4, '“Two peopl': 1, 'Don’t leav': 9, 'It must co': 8, 'Gnaw away ': 4, 'Problems a': 5, 'Most times': 6, 'So embrace': 3, 'Where are ': 2, 'Could you ': 1, 'Are you wi': 1, 'You should': 3, 'And that’s': 5, 'If you hav': 2, 'Only you c': 4, 'It’s a fac': 2, 'Nurture it': 4, 'Vision + d': 4, 'I’m amused': 3, 'Success is': 4, 'Similarly,': 3, 'This means': 4, 'The more y': 4, 'If you lea': 4, 'So become ': 6, 'Commit to ': 11, 'Nurture yo': 13, 'Focus on y': 6, 'Because I ': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_average_score(sentenceValue) -> int:\n",
        "    sumValues = 0\n",
        "    for entry in sentenceValue:\n",
        "        sumValues += sentenceValue[entry]\n",
        "\n",
        "    # Average value of a sentence from original text\n",
        "    average = int(sumValues / len(sentenceValue))\n",
        "\n",
        "    return average\n",
        "\n",
        "threshold = find_average_score(sentence_scores)\n",
        "print(\"Threshold:\", threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2e8u33eUPFM",
        "outputId": "7da24b98-1db9-4aa5-89f5-2cc7e3c51ad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(sentences, sentenceValue, threshold):\n",
        "    sentence_count = 0\n",
        "    summary = ''\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if sentence[:10] in sentenceValue and sentenceValue[sentence[:10]] > (threshold):\n",
        "            summary += \" \" + sentence\n",
        "            sentence_count += 1\n",
        "\n",
        "    return summary\n",
        "\n",
        "summary = generate_summary(sentences, sentence_scores, 1.5 * threshold)\n",
        "print(\"Summary:\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72Ej1XjnHJGi",
        "outputId": "908b23b4-fd05-4d6d-ecd0-b6a507b7db7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:  To be honest, I don’t have the answers. Same failure, yet different responses. Neither. Don’t leave it to other people or outside circumstances to motivate you because you will be let down every time. It must come from within you. Commit to it. Nurture your dreams. Don’t leave your dreams to chance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lengths of both original text and final_summary\n",
        "len(text), len(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yew_CQAr_AN1",
        "outputId": "1cce75ae-8137-4ff5-8201-77a0715dc7d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5889, 301)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TF-IDF (Term Frequency-Inverse Document Frequency)**\n",
        "\n",
        " TF-IDF is a common technique for measuring the importance of words in a document relative to a collection of documents. In this version, we use TF-IDF to score sentences and select those with the highest importance."
      ],
      "metadata": {
        "id": "gupxGGR8w1t2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Text = ''' Once upon a time, a tortoise lived on his own terms in a jungle. He was quiet, polite and non-interfering. In the same town lived a Hare who loved to talk about the many awards he had won for always finishing first in a race.\n",
        "One day, he approached the Tortoise and said, “Why don’t you learn to walk faster? If you do, we can race someday.” The Tortoise only smiled at him and moved on. The Hare was in a wicked mood. Every day, he would approach the Tortoise at the same place and pass the same comment.\n",
        "One fine day, when the Hare challenged him again, the Tortoise replied, “Alright, I accept the challenge.” He looked around and saw the other jungle animals clapping their hands and cheering him on.\n",
        "When the race began, the Hare overtook the Tortoise within no time. His speed was remarkably high, making him cover a considerable distance on the track. When he looked back and saw how far behind he had left the Tortoise, the Hare decided to stop running and rest for a while.\n",
        "He lay down under a huge banyan tree on one side of the track. The lovely shade of the leaves sent him into a deep slumber. Meanwhile, the Tortoise ran slowly without giving up and stopping.\n",
        "As time passed, he gradually caught up with the Hare, who was still sleeping. The Tortoise crossed by him and continued moving towards the winning line. Slowly but surely, the Tortoise reached the finish line and won the race.\n",
        "The entire town started clapping for the Tortoise. The loud cheers woke up the Hare from his deep sleep. He woke up, not realising what had happened. He rubbed his eyes and thought, “Gosh, the tortoise must still be struggling.”\n",
        "The Hare got up and dashed towards the winning post. When he got there, he saw that, to his surprise, the Tortoise was wearing the victory crown, and all the other animals were congratulating him. The Tortoise saw the Hare from a distance and smiled at him. The Hare sat down, regretting the action that made him lose the race against the slowest animal in the jungle. '''"
      ],
      "metadata": {
        "id": "TrnqsvTTxwuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(Text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLgBKXkZzjB_",
        "outputId": "8d675304-a093-483b-8099-efb79a282305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Once upon a time, a tortoise lived on his own terms in a jungle.',\n",
              " 'He was quiet, polite and non-interfering.',\n",
              " 'In the same town lived a Hare who loved to talk about the many awards he had won for always finishing first in a race.',\n",
              " 'One day, he approached the Tortoise and said, “Why don’t you learn to walk faster?',\n",
              " 'If you do, we can race someday.” The Tortoise only smiled at him and moved on.',\n",
              " 'The Hare was in a wicked mood.',\n",
              " 'Every day, he would approach the Tortoise at the same place and pass the same comment.',\n",
              " 'One fine day, when the Hare challenged him again, the Tortoise replied, “Alright, I accept the challenge.” He looked around and saw the other jungle animals clapping their hands and cheering him on.',\n",
              " 'When the race began, the Hare overtook the Tortoise within no time.',\n",
              " 'His speed was remarkably high, making him cover a considerable distance on the track.',\n",
              " 'When he looked back and saw how far behind he had left the Tortoise, the Hare decided to stop running and rest for a while.',\n",
              " 'He lay down under a huge banyan tree on one side of the track.',\n",
              " 'The lovely shade of the leaves sent him into a deep slumber.',\n",
              " 'Meanwhile, the Tortoise ran slowly without giving up and stopping.',\n",
              " 'As time passed, he gradually caught up with the Hare, who was still sleeping.',\n",
              " 'The Tortoise crossed by him and continued moving towards the winning line.',\n",
              " 'Slowly but surely, the Tortoise reached the finish line and won the race.',\n",
              " 'The entire town started clapping for the Tortoise.',\n",
              " 'The loud cheers woke up the Hare from his deep sleep.',\n",
              " 'He woke up, not realising what had happened.',\n",
              " 'He rubbed his eyes and thought, “Gosh, the tortoise must still be struggling.” \\nThe Hare got up and dashed towards the winning post.',\n",
              " 'When he got there, he saw that, to his surprise, the Tortoise was wearing the victory crown, and all the other animals were congratulating him.',\n",
              " 'The Tortoise saw the Hare from a distance and smiled at him.',\n",
              " 'The Hare sat down, regretting the action that made him lose the race against the slowest animal in the jungle.']"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def tfidf_summary(Text, summary_ratio=0.3):\n",
        "\n",
        "    # Split the text into sentences.\n",
        "    sentences = sent_tokenize(Text)\n",
        "\n",
        "    # Create a TF-IDF Vectorizer and fit it on the sentences.\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
        "\n",
        "    # Calculate the TF-IDF score for each sentence by summing the weights of the words.\n",
        "    sentence_scores = tfidf_matrix.sum(axis=1).flatten()\n",
        "\n",
        "    # Convert the sentence scores to a list and get the corresponding scores.\n",
        "    sentence_scores = np.array(sentence_scores).flatten()\n",
        "\n",
        "    # Sort sentences by their scores in descending order and select the top ones.\n",
        "    num_sentences = max(1, int(len(sentences) * summary_ratio))\n",
        "    top_sentence_indices = sentence_scores.argsort()[-num_sentences:][::-1]\n",
        "\n",
        "    # Construct the summary by selecting the top-scoring sentences.\n",
        "    summary = ' '.join([sentences[i] for i in sorted(top_sentence_indices)])\n",
        "    return summary\n",
        "\n",
        "summary = tfidf_summary(Text, summary_ratio=0.5)\n",
        "print(\"Summary:\", summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNrFnzLOxAOM",
        "outputId": "2b7ad361-43a9-4ade-8ce7-c876254818e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: In the same town lived a Hare who loved to talk about the many awards he had won for always finishing first in a race. One day, he approached the Tortoise and said, “Why don’t you learn to walk faster? If you do, we can race someday.” The Tortoise only smiled at him and moved on. Every day, he would approach the Tortoise at the same place and pass the same comment. One fine day, when the Hare challenged him again, the Tortoise replied, “Alright, I accept the challenge.” He looked around and saw the other jungle animals clapping their hands and cheering him on. His speed was remarkably high, making him cover a considerable distance on the track. When he looked back and saw how far behind he had left the Tortoise, the Hare decided to stop running and rest for a while. He lay down under a huge banyan tree on one side of the track. As time passed, he gradually caught up with the Hare, who was still sleeping. He rubbed his eyes and thought, “Gosh, the tortoise must still be struggling.” \n",
            "The Hare got up and dashed towards the winning post. When he got there, he saw that, to his surprise, the Tortoise was wearing the victory crown, and all the other animals were congratulating him. The Hare sat down, regretting the action that made him lose the race against the slowest animal in the jungle.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lengths of both original text and final_summary\n",
        "len(Text), len(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mB1Jr3V80ES",
        "outputId": "c9ed607a-a33d-4c20-a0db-d1099d77b45a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2007, 301)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TextRank**"
      ],
      "metadata": {
        "id": "k5TJ1lWAAeQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teXt = \"\"\" There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
        "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
        "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[3] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "I1GJEMBtAV91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(teXt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp3qBk4lBBWH",
        "outputId": "68e4112d-bcf6-4a02-84d7-d57293f157d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.',\n",
              " 'The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).',\n",
              " 'The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.',\n",
              " 'Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.',\n",
              " 'An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.',\n",
              " 'Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).',\n",
              " 'This problem is called multi-document summarization.',\n",
              " 'A related application is summarizing news articles.',\n",
              " 'Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.',\n",
              " 'Image collection summarization is another application example of automatic summarization.',\n",
              " 'It consists in selecting a representative set of images from a larger set of images.',\n",
              " '[3] A summary in this context is useful to show the most representative images of results in an image collection exploration system.',\n",
              " 'Video summarization is a related domain, where the system automatically creates a trailer of a long video.',\n",
              " 'This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.',\n",
              " 'Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured.']"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "def textrank_summary(teXt, summary_ratio=0.3):\n",
        "\n",
        "    # Step 1: Tokenize the text into sentences\n",
        "    sentences = sent_tokenize(teXt)\n",
        "\n",
        "    # Step 2: Create a TF-IDF Vectorizer and fit it on the sentences to get sentence embeddings.\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
        "\n",
        "    # Step 3: Calculate cosine similarity between each pair of sentences.\n",
        "    similarity_matrix = np.dot(tfidf_matrix, tfidf_matrix.T).toarray()\n",
        "\n",
        "    # Step 4: Build a graph where nodes are sentences and edges are weighted by cosine similarity.\n",
        "    nx_graph = nx.from_numpy_array(similarity_matrix)\n",
        "\n",
        "    # Step 5: Apply the PageRank algorithm to rank the sentences.\n",
        "    scores = nx.pagerank(nx_graph)\n",
        "\n",
        "    # Step 6: Rank sentences and select the top ones based on the summary ratio.\n",
        "    ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
        "    num_sentences = max(1, int(len(sentences) * summary_ratio))\n",
        "    top_sentences = [sentence for score, sentence in ranked_sentences[:num_sentences]]\n",
        "\n",
        "    # Step 7: Construct the final summary by joining the selected sentences.\n",
        "    summary = ' '.join(top_sentences)\n",
        "    return summary\n",
        "\n",
        "summary = textrank_summary(teXt, summary_ratio=0.5)\n",
        "print(\"Summary:\", summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KyQbqMPAnJe",
        "outputId": "491c0f49-ef6f-4570-e575-d5ec2062008b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. [3] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Image collection summarization is another application example of automatic summarization. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary. This problem is called multi-document summarization. The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lengths of both original text and final_summary\n",
        "len(teXt), len(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLpjoCQTBTFt",
        "outputId": "a630d631-916c-440f-c1ef-87f3e1ba177c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1869, 885)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    }
  ]
}